# -*- coding: utf-8 -*-
"""Untitled60.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y47jn1MXrYCq7QIsE5e7_6RPoge9h1t-
"""

import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud

# Download necessary NLTK data
try:
    stopwords.words('english')
except LookupError:
    nltk.download('stopwords')
    nltk.download('wordnet')
    nltk.download('punkt')

# Load the dataset
df = pd.read_csv('spam_ham_dataset.csv')
df.info()

df.head(10)

# PREPROCESSING AND CLEANING
df = df.drop('Unnamed: 0', axis=1)

df['label'] = df['label'].map({'ham': 0, 'spam': 1})
print("\nLabels converted to numerical format (spam=1, ham=0).")

lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

def clean_text(text):
    """
    Function to clean the raw text data.
    - Removes non-alphabetic characters
    - Converts to lowercase
    - Removes stop words
    - Lemmatizes words
    """
    text = re.sub(r'[^a-zA-Z]', ' ', text).lower()
    words = text.split()
    cleaned_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]
    return ' '.join(cleaned_words)

df['cleaned_text'] = df['text'].apply(clean_text)
print("Text cleaning and lemmatization complete.")
print("\n--- Data after Cleaning ---")
print(df.head())

# DATA VISUALIZATION
print("\n--- Generating Data Visualizations ---")
plt.figure(figsize=(8, 6))
df['label'].value_counts().plot(kind='pie', autopct='%1.1f%%', labels=['Ham', 'Spam'], colors=['skyblue', 'salmon'])
plt.title('Distribution of Spam vs. Ham Messages')
plt.ylabel('')
plt.show()

# Word Clouds for Spam and Ham
ham_text = " ".join(df[df['label'] == 0]['cleaned_text'])
spam_text = " ".join(df[df['label'] == 1]['cleaned_text'])

plt.figure(figsize=(10, 7))
wordcloud_ham = WordCloud(width=800, height=400, background_color='white').generate(ham_text)
plt.imshow(wordcloud_ham, interpolation='bilinear')
plt.title('Most Frequent Words in Ham Messages')
plt.axis('off')
plt.show()

plt.figure(figsize=(10, 7))
wordcloud_spam = WordCloud(width=800, height=400, background_color='black', colormap='Reds').generate(spam_text)
plt.imshow(wordcloud_spam, interpolation='bilinear')
plt.title('Most Frequent Words in Spam Messages')
plt.axis('off')
plt.show()

# FEATURE ENGINEERING (TF-IDF)
print("\n--- Performing Feature Engineering with TF-IDF ---")
tfidf_vectorizer = TfidfVectorizer(max_features=3000)
X = tfidf_vectorizer.fit_transform(df['cleaned_text']).toarray()
y = df['label']
print(f"Data has been converted into a TF-IDF matrix of shape: {X.shape}")

# MODEL TRAINING
print("\nSplitting Data and Training Models")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print(f"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}")

models = {
    'Naive Bayes': MultinomialNB(),
    'SVM': SVC(kernel='linear', random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42)
}

for name, model in models.items():
    print(f"Training {name}...")
    model.fit(X_train, y_train)
print("All models trained successfully.")

print("\n--- Evaluating Models ---")
results = {}

for name, model in models.items():
    print(f"\n----- Evaluating: {name} -----")
    y_pred = model.predict(X_test)

    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    results[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1}

    # Print Classification Report
    print("Classification Report:")
    print(classification_report(y_test, y_pred, target_names=['Ham', 'Spam']))

    # Plot Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(f'Confusion Matrix for {name}')
    plt.show()

# FINAL RESULTS COMPARISON
print("\n Final Model Comparison ")

results_df = pd.DataFrame(results).T
print(results_df)

# Plotting the comparison
results_df.plot(kind='bar', figsize=(12, 7))
plt.title('Comparison of Model Performance Metrics')
plt.ylabel('Score')
plt.xticks(rotation=0)
plt.legend(loc='lower right')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

print("\nProject complete. Naive Bayes typically performs best for this task due to its effectiveness with text data and handling of high-dimensional feature spaces from TF-IDF.")

# 8. PREDICTION ON NEW MESSAGES
print("\n Testing Models with New, Unseen Messages")

def predict_message(message, model, vectorizer):
    """
    Takes a raw text message and predicts if it's spam or ham.
    - message: string, the input message.
    - model: a trained scikit-learn classifier.
    - vectorizer: the fitted TfidfVectorizer.
    """

    cleaned_message = clean_text(message)

    message_tfidf = vectorizer.transform([cleaned_message])


    if isinstance(model, SVC) or isinstance(model, DecisionTreeClassifier):
        message_tfidf = message_tfidf.toarray()

    prediction_code = model.predict(message_tfidf)[0]

    return "Spam" if prediction_code == 1 else "Ham"

#Example Messages to Test
new_messages = [
    "Congratulations! You've won a $1,000 Walmart gift card. Go to http://bit.ly/xyz to claim now.",
    "Hey, are we still on for lunch tomorrow at 1 PM? Let me know.",
    "URGENT: Your account has been suspended. Please verify your payment details immediately to avoid closure.",
    "Thanks for your order. Your package will be delivered by Tuesday."
]

for message in new_messages:
    print(f"\nOriginal Message: \"{message}\"")
    for name, model in models.items():
        prediction = predict_message(message, model, tfidf_vectorizer)
        print(f"  -> Prediction ({name}): {prediction}")

