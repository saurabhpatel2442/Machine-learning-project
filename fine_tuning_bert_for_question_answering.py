# -*- coding: utf-8 -*-
"""Fine-Tuning BERT for Question Answering

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZlDCi-fOJdu6DygavpZ2mxGDqauIOr6b
"""

!pip install torch transformers datasets evaluate pandas numpy tqdm

import pandas as pd
import numpy as np
import torch
import json
import os
import glob
from torch.utils.data import Dataset, DataLoader
from transformers import (
    BertTokenizerFast,
    BertForQuestionAnswering,
    Trainer,
    TrainingArguments,
    default_data_collator
)
from datasets import Dataset as HFDataset
import evaluate
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

class SQuADDataPreprocessor:
    """Preprocessor for SQuAD dataset with sliding window support"""

    def __init__(self, tokenizer, max_length=384, doc_stride=128):
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.doc_stride = doc_stride

    def load_squad_csv(self, csv_path):
        """Load SQuAD data from CSV file"""
        df = pd.read_csv('SQuAD-v1.1.csv')

        print("Available columns:", df.columns.tolist())

        # Check for different possible column name variations
        context_col = None
        question_col = None
        answer_col = None
        answer_start_col = None

        # Find the correct column names
        for col in df.columns:
            col_lower = col.lower()
            if 'context' in col_lower:
                context_col = col
            elif 'question' in col_lower:
                question_col = col
            elif 'answer' in col_lower and 'start' not in col_lower and 'end' not in col_lower:
                answer_col = col
            elif 'answer_start' in col_lower or (col_lower == 'answer_start'):
                answer_start_col = col

        # Check if we found all required columns
        missing_cols = []
        if context_col is None:
            missing_cols.append('context')
        if question_col is None:
            missing_cols.append('question')
        if answer_col is None:
            missing_cols.append('answer/answer_text')
        if answer_start_col is None:
            missing_cols.append('answer_start')

        if missing_cols:
            raise ValueError(f"Could not find columns for: {missing_cols}. Available columns: {df.columns.tolist()}")

        print(f"Using columns - Context: '{context_col}', Question: '{question_col}', Answer: '{answer_col}', Answer Start: '{answer_start_col}'")

        # Convert to the format expected by the preprocessor
        examples = []
        for idx, row in df.iterrows():
            # Skip rows with missing data
            if pd.isna(row[context_col]) or pd.isna(row[question_col]) or pd.isna(row[answer_col]) or pd.isna(row[answer_start_col]):
                continue

            example = {
                'id': str(idx),
                'question': str(row[question_col]).strip(),
                'context': str(row[context_col]).strip(),
                'answers': {
                    'text': [str(row[answer_col]).strip()],
                    'answer_start': [int(row[answer_start_col])]
                }
            }
            examples.append(example)

        print(f"Loaded {len(examples)} valid examples from CSV")
        return examples

    def preprocess_function(self, examples):
        """Preprocess examples with sliding window for long contexts"""
        questions = [q.strip() for q in examples["question"]]
        inputs = self.tokenizer(
            questions,
            examples["context"],
            max_length=self.max_length,
            truncation="only_second",
            stride=self.doc_stride,
            return_overflowing_tokens=True,
            return_offsets_mapping=True,
            padding="max_length",
        )

        offset_mapping = inputs.pop("offset_mapping")
        sample_map = inputs.pop("overflow_to_sample_mapping")
        answers = examples["answers"]
        start_positions = []
        end_positions = []

        for i, offsets in enumerate(offset_mapping):
            input_ids = inputs["input_ids"][i]
            cls_index = input_ids.index(self.tokenizer.cls_token_id)
            sequence_ids = inputs.sequence_ids(i)

            sample_index = sample_map[i]
            answer = answers[sample_index]

            if len(answer["answer_start"]) == 0:
                start_positions.append(cls_index)
                end_positions.append(cls_index)
            else:
                start_char = answer["answer_start"][0]
                end_char = start_char + len(answer["text"][0])

                token_start_index = 0
                while sequence_ids[token_start_index] != 1:
                    token_start_index += 1

                token_end_index = len(input_ids) - 1
                while sequence_ids[token_end_index] != 1:
                    token_end_index -= 1

                if not (offsets[token_start_index][0] <= start_char and
                       offsets[token_end_index][1] >= end_char):
                    start_positions.append(cls_index)
                    end_positions.append(cls_index)
                else:
                    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:
                        token_start_index += 1
                    start_positions.append(token_start_index - 1)

                    while offsets[token_end_index][1] >= end_char:
                        token_end_index -= 1
                    end_positions.append(token_end_index + 1)

        inputs["start_positions"] = start_positions
        inputs["end_positions"] = end_positions
        return inputs

class SQuADTrainer:
    """Trainer class for BERT Question Answering"""

    def __init__(self, model_name="bert-base-uncased", max_length=384, doc_stride=128):
        self.model_name = model_name
        self.max_length = max_length
        self.doc_stride = doc_stride

        # Load tokenizer and model
        self.tokenizer = BertTokenizerFast.from_pretrained(model_name)
        self.model = BertForQuestionAnswering.from_pretrained(model_name)

        # Initialize preprocessor
        self.preprocessor = SQuADDataPreprocessor(
            self.tokenizer, max_length, doc_stride
        )

        # Load metrics
        self.metric = evaluate.load("squad")

    def prepare_data(self, csv_path, test_size=0.1):
        """Load and prepare training and validation data"""
        print("Loading data from CSV...")
        examples = self.preprocessor.load_squad_csv(csv_path)

        # Split data
        split_idx = int(len(examples) * (1 - test_size))
        train_examples = examples[:split_idx]
        val_examples = examples[split_idx:]

        print(f"Training examples: {len(train_examples)}")
        print(f"Validation examples: {len(val_examples)}")

        # Convert to HuggingFace datasets
        train_dataset = HFDataset.from_list(train_examples)
        val_dataset = HFDataset.from_list(val_examples)

        # Preprocess
        print("Preprocessing training data...")
        train_dataset = train_dataset.map(
            self.preprocessor.preprocess_function,
            batched=True,
            remove_columns=train_dataset.column_names,
        )

        print("Preprocessing validation data...")
        val_dataset = val_dataset.map(
            self.preprocessor.preprocess_function,
            batched=True,
            remove_columns=val_dataset.column_names,
        )

        return train_dataset, val_dataset, val_examples

    def compute_metrics(self, eval_pred):
        """Compute F1 and Exact Match metrics"""
        predictions, labels = eval_pred
        start_predictions, end_predictions = predictions

        # This is a simplified metric computation
        # In practice, you'd want to implement proper SQuAD evaluation
        start_predictions = np.argmax(start_predictions, axis=1)
        end_predictions = np.argmax(end_predictions, axis=1)

        # Calculate accuracy for start and end positions
        start_accuracy = (start_predictions == labels[0]).mean()
        end_accuracy = (end_predictions == labels[1]).mean()
        exact_match = ((start_predictions == labels[0]) &
                      (end_predictions == labels[1])).mean()

        return {
            "start_accuracy": start_accuracy,
            "end_accuracy": end_accuracy,
            "exact_match": exact_match,
        }

    def train(self, train_dataset, val_dataset, output_dir="./bert-qa-finetuned"):
        """Train the BERT model"""
        training_args = TrainingArguments(
            output_dir=output_dir,
            eval_strategy="epoch",  # Changed from evaluation_strategy
            save_strategy="epoch",
            learning_rate=3e-5,
            per_device_train_batch_size=16,
            per_device_eval_batch_size=16,
            num_train_epochs=1,  # Reduced from 3 to 1 epoch for faster training
            weight_decay=0.01,
            warmup_steps=100,  # Reduced warmup steps for shorter training
            logging_dir="./logs",
            logging_steps=50,  # More frequent logging for shorter training
            save_total_limit=2,
            load_best_model_at_end=True,
            metric_for_best_model="exact_match",
            greater_is_better=True,
            report_to=[],  # Disable all logging services
            run_name=f"bert-qa-{output_dir.split('/')[-1]}",  # Set custom run name
        )

        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            tokenizer=self.tokenizer,
            data_collator=default_data_collator,
            compute_metrics=self.compute_metrics,
        )

        print("Starting training...")
        trainer.train()

        print("Saving model...")
        trainer.save_model()
        self.tokenizer.save_pretrained(output_dir)

        return trainer

class BERTQAInference:
    """Inference system for real-time question answering"""

    def __init__(self, model_path="./bert-qa-finetuned", max_length=384):
        self.max_length = max_length

        # Load fine-tuned model and tokenizer
        print("Loading fine-tuned model...")
        self.tokenizer = BertTokenizerFast.from_pretrained(model_path)
        self.model = BertForQuestionAnswering.from_pretrained(model_path)
        self.model.eval()

        if torch.cuda.is_available():
            self.model.cuda()

    def predict(self, question, context, return_confidence=False):
        """Get answer span for a question-context pair"""
        # Tokenize inputs
        inputs = self.tokenizer(
            question,
            context,
            max_length=self.max_length,
            truncation=True,
            padding=True,
            return_tensors="pt"
        )

        if torch.cuda.is_available():
            inputs = {k: v.cuda() for k, v in inputs.items()}

        # Get predictions
        with torch.no_grad():
            outputs = self.model(**inputs)
            start_logits = outputs.start_logits
            end_logits = outputs.end_logits

        # Get the most likely beginning and end of answer
        start_idx = torch.argmax(start_logits, dim=1).item()
        end_idx = torch.argmax(end_logits, dim=1).item()

        # Get confidence scores
        start_confidence = torch.softmax(start_logits, dim=1)[0][start_idx].item()
        end_confidence = torch.softmax(end_logits, dim=1)[0][end_idx].item()
        confidence = (start_confidence + end_confidence) / 2

        # Extract answer from tokens
        input_ids = inputs["input_ids"][0]
        tokens = self.tokenizer.convert_ids_to_tokens(input_ids)

        if start_idx <= end_idx and start_idx < len(tokens) and end_idx < len(tokens):
            answer_tokens = tokens[start_idx:end_idx + 1]
            answer = self.tokenizer.convert_tokens_to_string(answer_tokens)

            # Clean up the answer
            answer = answer.replace(" ##", "").strip()
        else:
            answer = ""
            confidence = 0.0

        if return_confidence:
            return answer, confidence
        return answer

    def batch_predict(self, questions, contexts):
        """Predict answers for multiple question-context pairs"""
        results = []
        for question, context in zip(questions, contexts):
            answer, confidence = self.predict(question, context, return_confidence=True)
            results.append({
                'question': question,
                'context': context[:100] + "..." if len(context) > 100 else context,
                'answer': answer,
                'confidence': confidence
            })
        return results

def find_squad_csv():
    """Automatically find SQuAD CSV file in the current directory"""
    current_dir = os.getcwd()
    print(f"Current directory: {current_dir}")

    # List all files in current directory
    all_files = os.listdir(current_dir)
    csv_files = [f for f in all_files if f.endswith('.csv')]

    print(f"All files in directory: {all_files}")
    print(f"CSV files found: {csv_files}")

    # Look for SQuAD-related files
    squad_patterns = ['squad', 'SQuAD', 'SQUAD']
    possible_files = []

    for csv_file in csv_files:
        for pattern in squad_patterns:
            if pattern in csv_file:
                possible_files.append(csv_file)
                break

    if possible_files:
        print(f"Possible SQuAD files found: {possible_files}")
        return possible_files[0]  # Return the first match

    if csv_files:
        print(f"No SQuAD-specific files found, but CSV files are available: {csv_files}")
        return csv_files[0]  # Return the first CSV file

    return None

def main():
    """Main function to run the complete pipeline"""

    print("=== BERT Question Answering Fine-tuning Pipeline ===\n")

    # Step 0: Find the CSV file automatically
    print("0. Looking for SQuAD CSV file...")
    csv_path = find_squad_csv()

    if csv_path is None:
        print("❌ No CSV files found in the current directory!")
        print("\n📋 To fix this issue:")
        print("1. Make sure your SQuAD CSV file is uploaded to this directory")
        print("2. The file should be named something like 'SQuAD-v1.1.csv' or 'squad_data.csv'")
        print("3. Or update the CSV_PATH variable in the code with the correct path")
        print("\n💡 If you're using Google Colab:")
        print("   - Upload your file using the file browser on the left")
        print("   - Or use: from google.colab import files; files.upload()")
        return

    print(f"✅ Found CSV file: {csv_path}")

    # Configuration
    MODEL_OUTPUT_DIR = "./bert-qa-finetuned"

    # Step 1: Initialize trainer
    print("1. Initializing BERT trainer...")
    trainer = SQuADTrainer(
        model_name="bert-base-uncased",
        max_length=384,
        doc_stride=128
    )

    # Step 2: Prepare data
    print("\n2. Preparing data...")
    try:
        train_dataset, val_dataset, val_examples = trainer.prepare_data(
            csv_path, test_size=0.1
        )
    except FileNotFoundError:
        print(f"❌ Error: Could not find {csv_path}")
        print("\n📋 To fix this issue:")
        print("1. Make sure your SQuAD CSV file is uploaded to this directory")
        print("2. Check the file name and path")
        print("3. If using Google Colab, upload the file using the file browser")
        return
    except Exception as e:
        print(f"❌ Error preparing data: {e}")
        print("\n📋 Troubleshooting:")
        print("1. Check if your CSV has the required columns: context, question, answer, answer_start")
        print("2. Make sure the CSV is properly formatted")
        print("3. Check for any missing or corrupted data")
        return

    # Step 3: Train model
    print("\n3. Training model...")
    trained_model = trainer.train(train_dataset, val_dataset, MODEL_OUTPUT_DIR)

    # Step 4: Initialize inference system
    print("\n4. Setting up inference system...")
    qa_system = BERTQAInference(MODEL_OUTPUT_DIR)

    # Step 5: Demo inference
    print("\n5. Running demo inference...")

    # Example questions (you can modify these)
    demo_contexts = [
        "The Amazon rainforest is a moist broadleaf tropical rainforest that covers most of the Amazon basin of South America. The basin is 7,000,000 square kilometers, of which 5,500,000 square kilometers are covered by the rainforest.",
        "Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation."
    ]

    demo_questions = [
        "How large is the Amazon basin?",
        "What does Python's design philosophy emphasize?"
    ]

    results = qa_system.batch_predict(demo_questions, demo_contexts)

    print("\nDemo Results:")
    print("-" * 80)
    for i, result in enumerate(results, 1):
        print(f"Example {i}:")
        print(f"Question: {result['question']}")
        print(f"Context: {result['context']}")
        print(f"Answer: {result['answer']}")
        print(f"Confidence: {result['confidence']:.3f}")
        print("-" * 80)

    # Step 6: Interactive mode
    print("\n6. Interactive Question Answering")
    print("Enter 'quit' to exit")

    while True:
        print("\n" + "="*50)
        context = input("Enter context (or 'quit' to exit): ").strip()
        if context.lower() == 'quit':
            break

        question = input("Enter question: ").strip()
        if question.lower() == 'quit':
            break

        answer, confidence = qa_system.predict(question, context, return_confidence=True)

        print(f"\nAnswer: {answer}")
        print(f"Confidence: {confidence:.3f}")

# Additional utility functions
def evaluate_model_on_squad(model_path, test_csv_path):
    """Evaluate the fine-tuned model on a test set"""
    qa_system = BERTQAInference(model_path)

    # Load test data
    test_df = pd.read_csv(test_csv_path)

    correct = 0
    total = 0

    print("Evaluating model...")
    for _, row in tqdm(test_df.iterrows(), total=len(test_df)):
        predicted_answer = qa_system.predict(row['question'], row['context'])
        actual_answer = row['answer_text']

        # Simple exact match evaluation
        if predicted_answer.strip().lower() == actual_answer.strip().lower():
            correct += 1
        total += 1

    accuracy = correct / total
    print(f"Exact Match Accuracy: {accuracy:.3f}")
    return accuracy

def create_sample_csv():
    """Create a sample SQuAD CSV for testing"""
    sample_data = {
        'title': ['Amazon', 'Python', 'Machine Learning'],
        'context': [
            "The Amazon rainforest is a moist broadleaf tropical rainforest that covers most of the Amazon basin of South America. The basin is 7,000,000 square kilometers, of which 5,500,000 square kilometers are covered by the rainforest.",
            "Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation. Python is dynamically typed and garbage-collected.",
            "Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data."
        ],
        'question': [
            "How large is the Amazon basin?",
            "What does Python's design philosophy emphasize?",
            "What is machine learning?"
        ],
        'answer': [
            "7,000,000 square kilometers",
            "code readability",
            "a method of data analysis that automates analytical model building"
        ],
        'answer_start': [85, 106, 18],
        'answer_end': [107, 121, 82]
    }

    df = pd.DataFrame(sample_data)
    df.to_csv('sample_squad.csv', index=False)
    print("✅ Created sample_squad.csv for testing")
    return 'sample_squad.csv'

if __name__ == "__main__":
    # If no CSV files are found, create a sample for testing
    if find_squad_csv() is None:
        print("🔧 No CSV files found. Creating a sample dataset for testing...")
        create_sample_csv()
        print("🚀 Now running with sample data. Replace 'sample_squad.csv' with your actual SQuAD dataset.\n")

    main()